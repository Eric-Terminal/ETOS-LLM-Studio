// ============================================================================
// ChatViewModel.swift
// ============================================================================ 
// ETOS LLM Studio Watch App æ ¸å¿ƒè§†å›¾æ¨¡å‹æ–‡ä»¶ (å·²é‡æ„)
//
// åŠŸèƒ½ç‰¹æ€§:
// - é©±åŠ¨ä¸»è§†å›¾ (ContentView) çš„æ‰€æœ‰ä¸šåŠ¡é€»è¾‘
// - ç®¡ç†åº”ç”¨çŠ¶æ€ï¼ŒåŒ…æ‹¬æ¶ˆæ¯ã€ä¼šè¯ã€è®¾ç½®ç­‰
// - å¤„ç†ç½‘ç»œè¯·æ±‚ã€æ•°æ®æ“ä½œå’Œç”¨æˆ·äº¤äº’
// ============================================================================

import Foundation
import SwiftUI
import WatchKit
import os.log
import Combine
import Shared
import AVFoundation
import AVFAudio

private let logger = Logger(subsystem: "com.ETOS.LLM.Studio", category: "ChatViewModel")

@MainActor
class ChatViewModel: ObservableObject {
    
    // MARK: - @Published å±æ€§ (UI çŠ¶æ€)
    
    @Published var messages: [ChatMessage] = []
    @Published var allMessagesForSession: [ChatMessage] = []
    @Published var isHistoryFullyLoaded: Bool = false
    @Published var userInput: String = ""
    @Published var messageToEdit: ChatMessage?
    @Published var activeSheet: ActiveSheet?
    
    @Published var chatSessions: [ChatSession] = []
    @Published var currentSession: ChatSession?
    
    @Published var providers: [Provider] = []
    @Published var selectedModel: RunnableModel?
    @Published var activatedModels: [RunnableModel] = []
    
    @Published var memories: [MemoryItem] = []
    
    // é‡æ„: ç”¨äºç®¡ç†UIçŠ¶æ€ï¼Œä¸æ•°æ®æ¨¡å‹åˆ†ç¦»
    @Published var reasoningExpandedState: [UUID: Bool] = [:]
    @Published var toolCallsExpandedState: [UUID: Bool] = [:]
    @Published var isSendingMessage: Bool = false
    @Published var speechModels: [RunnableModel] = []
    @Published var selectedSpeechModel: RunnableModel?
    @Published var selectedEmbeddingModel: RunnableModel?
    @Published var isSpeechRecorderPresented: Bool = false
    @Published var isRecordingSpeech: Bool = false
    @Published var speechTranscriptionInProgress: Bool = false
    @Published var speechErrorMessage: String?
    @Published var showSpeechErrorAlert: Bool = false
    @Published var recordingDuration: TimeInterval = 0
    @Published var waveformSamples: [CGFloat] = Array(repeating: 0, count: 24)
    
    // MARK: - ç”¨æˆ·åå¥½è®¾ç½® (AppStorage)
    
    @AppStorage("enableMarkdown") var enableMarkdown: Bool = true
    @AppStorage("enableBackground") var enableBackground: Bool = true
    @AppStorage("backgroundBlur") var backgroundBlur: Double = 10.0
    @AppStorage("backgroundOpacity") var backgroundOpacity: Double = 0.7
    @AppStorage("aiTemperature") var aiTemperature: Double = 0.7
    @AppStorage("aiTopP") var aiTopP: Double = 1.0
    @AppStorage("systemPrompt") var systemPrompt: String = ""
    @AppStorage("maxChatHistory") var maxChatHistory: Int = 0
    @AppStorage("enableStreaming") var enableStreaming: Bool = false
    @AppStorage("lazyLoadMessageCount") var lazyLoadMessageCount: Int = 10
    @AppStorage("currentBackgroundImage") var currentBackgroundImage: String = ""
    @AppStorage("enableAutoRotateBackground") var enableAutoRotateBackground: Bool = true
    @AppStorage("enableAutoSessionNaming") var enableAutoSessionNaming: Bool = true
    @AppStorage("enableMemory") var enableMemory: Bool = true
    @AppStorage("enableMemoryWrite") var enableMemoryWrite: Bool = true
    @AppStorage("enableLiquidGlass") var enableLiquidGlass: Bool = false
    @AppStorage("sendSpeechAsAudio") var sendSpeechAsAudio: Bool = false
    @AppStorage("enableSpeechInput") var enableSpeechInput: Bool = false
    @AppStorage("speechModelIdentifier") var speechModelIdentifier: String = ""
    @AppStorage("memoryEmbeddingModelIdentifier") var memoryEmbeddingModelIdentifier: String = ""
    @AppStorage("includeSystemTimeInPrompt") var includeSystemTimeInPrompt: Bool = false
    
    // MARK: - å…¬å¼€å±æ€§
    
    @Published var backgroundImages: [String] = []
    
    var currentBackgroundImageUIImage: UIImage? {
        guard !currentBackgroundImage.isEmpty else { return nil }
        let fileURL = ConfigLoader.getBackgroundsDirectory().appendingPathComponent(currentBackgroundImage)
        return UIImage(contentsOfFile: fileURL.path)
    }
    
    var embeddingModelOptions: [RunnableModel] {
        providers.flatMap { provider in
            provider.models.map { RunnableModel(provider: provider, model: $0) }
        }
    }
    
    // MARK: - ç§æœ‰å±æ€§
    
    private var extendedSession: WKExtendedRuntimeSession?
    private let chatService: ChatService
    private var cancellables = Set<AnyCancellable>()
    private var audioRecorder: AVAudioRecorder?
    private var speechRecordingURL: URL?
    private var recordingStartDate: Date?
    private var recordingTimer: Timer?
    private let waveformSampleCount: Int = 24
    
    // MARK: - åˆå§‹åŒ–

    /// ä¸»åº”ç”¨ä½¿ç”¨çš„ä¾¿åˆ©åˆå§‹åŒ–æ–¹æ³•
    convenience init() {
        self.init(chatService: .shared)
    }

    /// ç”¨äºæµ‹è¯•å’Œä¾èµ–æ³¨å…¥çš„æŒ‡å®šåˆå§‹åŒ–æ–¹æ³•
    internal init(chatService: ChatService) {
        logger.info("ğŸš€ [ViewModel] ChatViewModel initializing with specific service...")
        self.chatService = chatService
        self.backgroundImages = ConfigLoader.loadBackgroundImages()

        // è®¾ç½® Combine è®¢é˜…
        setupSubscriptions()
        
        // ç›‘å¬åº”ç”¨è¿”å›å‰å°äº‹ä»¶ï¼Œä»¥é‡ç½®å¯èƒ½å¡ä½çš„çŠ¶æ€
        NotificationCenter.default.addObserver(self, selector: #selector(handleDidBecomeActive), name: WKApplication.didBecomeActiveNotification, object: nil)

        // è‡ªåŠ¨è½®æ¢èƒŒæ™¯é€»è¾‘
        rotateBackgroundImageIfNeeded()
        
        logger.info("  - ViewModel initialized and subscribed to a ChatService instance.")
    }
    
    @objc private func handleDidBecomeActive() {
        logger.info("App became active, checking for interrupted state.")
        // [BUG FIX] This logic was too aggressive. It incorrectly assumed a request
        // was interrupted when the app became active while a request was in flight.
        // The underlying URLSession's timeout is the correct way to handle this.
        // if isSendingMessage {
        //     logger.warning("  - Message sending was interrupted. Resetting state.")
        //     isSendingMessage = false
        //     chatService.addErrorMessage("ç½‘ç»œè¯·æ±‚å·²ä¸­æ–­ï¼Œè¯·é‡è¯•ã€‚")
        // }
    }
    
    private func setupSubscriptions() {
        chatService.chatSessionsSubject
            .receive(on: DispatchQueue.main)
            .assign(to: \.chatSessions, on: self)
            .store(in: &cancellables)
            
        chatService.currentSessionSubject
            .receive(on: DispatchQueue.main)
            .assign(to: \.currentSession, on: self)
            .store(in: &cancellables)
            
        chatService.messagesForSessionSubject
            .receive(on: DispatchQueue.main)
            .assign(to: \.allMessagesForSession, on: self)
            .store(in: &cancellables)
        
        chatService.providersSubject
            .receive(on: DispatchQueue.main)
            .sink { [weak self] providers in
                guard let self = self else { return }
                self.providers = providers
                self.activatedModels = self.chatService.activatedRunnableModels
                self.speechModels = self.chatService.activatedSpeechModels
                self.syncSpeechModelSelection()
                self.syncEmbeddingModelSelection()
            }
            .store(in: &cancellables)

        chatService.selectedModelSubject
            .receive(on: DispatchQueue.main)
            .assign(to: \.selectedModel, on: self)
            .store(in: &cancellables)
            
        chatService.requestStatusSubject
            .receive(on: DispatchQueue.main)
            .sink { [weak self] status in
                switch status {
                case .started:
                    self?.isSendingMessage = true
                    self?.startExtendedSession()
                case .finished, .error, .cancelled:
                    self?.isSendingMessage = false
                    self?.stopExtendedSession()
                @unknown default:
                    // ä¸ºæœªæ¥å¯èƒ½çš„çŠ¶æ€ä¿ç•™ï¼Œä¸åšä»»ä½•æ“ä½œ
                    break
                }
            }
            .store(in: &cancellables)
        
        $allMessagesForSession
            .receive(on: DispatchQueue.main)
            .sink { [weak self] _ in
                self?.updateDisplayedMessages()
            }
            .store(in: &cancellables)
            
        MemoryManager.shared.memoriesPublisher
            .receive(on: DispatchQueue.main)
            .assign(to: \.memories, on: self)
            .store(in: &cancellables)

        NotificationCenter.default.publisher(for: .syncBackgroundsUpdated)
            .receive(on: DispatchQueue.main)
            .sink { [weak self] _ in
                self?.refreshBackgroundImages()
            }
            .store(in: &cancellables)
        
        syncSpeechModelSelection()
        syncEmbeddingModelSelection()
    }
    
    private func rotateBackgroundImageIfNeeded() {
        refreshBackgroundImages()
        guard enableAutoRotateBackground, !backgroundImages.isEmpty else { return }
        let availableBackgrounds = backgroundImages.filter { $0 != currentBackgroundImage }
        currentBackgroundImage = availableBackgrounds.randomElement() ?? backgroundImages.randomElement() ?? ""
        logger.info("  - è‡ªåŠ¨è½®æ¢èƒŒæ™¯ã€‚æ–°èƒŒæ™¯: \(self.currentBackgroundImage)")
    }
    
    // MARK: - å…¬å¼€æ–¹æ³• (è§†å›¾æ“ä½œ)
    
    // MARK: æ¶ˆæ¯æµ
    
    func sendMessage() {
        logger.info("âœ‰ï¸ [ViewModel] sendMessage called.")
        let userMessageContent = userInput
        guard !userMessageContent.isEmpty, !isSendingMessage else { return }
        userInput = ""
        
        Task {
            await chatService.sendAndProcessMessage(
                content: userMessageContent,
                aiTemperature: aiTemperature,
                aiTopP: aiTopP,
                systemPrompt: systemPrompt,
                maxChatHistory: maxChatHistory,
                enableStreaming: enableStreaming,
                enhancedPrompt: currentSession?.enhancedPrompt,
                enableMemory: enableMemory,
                enableMemoryWrite: enableMemoryWrite,
                includeSystemTime: includeSystemTimeInPrompt
            )
        }
    }
    
    func addErrorMessage(_ content: String) {
        chatService.addErrorMessage(content)
    }
    
    func retryLastMessage() {
        // ç§»é™¤ isSendingMessage ä¿æŠ¤ï¼Œå…è®¸ä¸­æ–­å½“å‰æ­£åœ¨å‘é€çš„è¯·æ±‚ã€‚
        // ChatService ä¸­çš„ retryLastMessage ä¼šå¤„ç†é‡ç½®æ¶ˆæ¯å†å²çš„é€»è¾‘ã€‚
        Task {
            await chatService.retryLastMessage(
                aiTemperature: aiTemperature,
                aiTopP: aiTopP,
                systemPrompt: systemPrompt,
                maxChatHistory: maxChatHistory,
                enableStreaming: enableStreaming,
                enhancedPrompt: currentSession?.enhancedPrompt,
                enableMemory: enableMemory,
                enableMemoryWrite: enableMemoryWrite,
                includeSystemTime: includeSystemTimeInPrompt
            )
        }
    }
    
    // MARK: è¯­éŸ³è¾“å…¥
    
    func setSelectedSpeechModel(_ model: RunnableModel?) {
        selectedSpeechModel = model
        let newIdentifier = model?.id ?? ""
        if speechModelIdentifier != newIdentifier {
            speechModelIdentifier = newIdentifier
        }
    }
    
    func setSelectedEmbeddingModel(_ model: RunnableModel?) {
        selectedEmbeddingModel = model
        let newIdentifier = model?.id ?? ""
        if memoryEmbeddingModelIdentifier != newIdentifier {
            memoryEmbeddingModelIdentifier = newIdentifier
        }
    }
    
    func appendTranscribedText(_ text: String) {
        let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !trimmed.isEmpty else { return }
        if userInput.isEmpty {
            userInput = trimmed
        } else {
            let needsSpace = !(userInput.last?.isWhitespace ?? true)
            userInput += (needsSpace ? " " : "") + trimmed
        }
    }
    
    func clearUserInput() {
        userInput = ""
    }
    
    func beginSpeechInputFlow() {
        guard enableSpeechInput else {
            presentSpeechError("è¯·å…ˆåœ¨é«˜çº§è®¾ç½®ä¸­å¼€å¯è¯­è¨€è¾“å…¥åŠŸèƒ½ã€‚")
            return
        }
        if !sendSpeechAsAudio {
            guard !speechModels.isEmpty else {
                presentSpeechError("æš‚æ— å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·å…ˆåœ¨æ¨¡å‹è®¾ç½®ä¸­å¯ç”¨ã€‚")
                return
            }
            guard selectedSpeechModel != nil else {
                presentSpeechError("è¯·é€‰æ‹©ä¸€ä¸ªè¯­éŸ³è½¬æ–‡å­—æ¨¡å‹ã€‚")
                return
            }
        }
        speechErrorMessage = nil
        showSpeechErrorAlert = false
        isSpeechRecorderPresented = true
    }
    
    func startSpeechRecording() async {
        guard !isRecordingSpeech else { return }
        guard enableSpeechInput else {
            presentSpeechError("è¯­è¨€è¾“å…¥å·²è¢«å…³é—­ã€‚")
            isSpeechRecorderPresented = false
            return
        }
        if !sendSpeechAsAudio {
            guard selectedSpeechModel != nil else {
                presentSpeechError("å°šæœªé€‰æ‹©è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹ã€‚")
                isSpeechRecorderPresented = false
                return
            }
        }
        
        let permissionGranted = await requestMicrophonePermission()
        guard permissionGranted else {
            presentSpeechError("éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åˆ°è®¾ç½®ä¸­å¼€å¯ã€‚")
            isSpeechRecorderPresented = false
            return
        }
        
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(.playAndRecord, mode: .spokenAudio, options: [.duckOthers])
            try session.setActive(true, options: .notifyOthersOnDeactivation)
            
            if let existingURL = speechRecordingURL {
                try? FileManager.default.removeItem(at: existingURL)
            }
            let targetURL = FileManager.default.temporaryDirectory.appendingPathComponent("speech-\(UUID().uuidString).wav")
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatLinearPCM),
                AVSampleRateKey: 16000,
                AVNumberOfChannelsKey: 1,
                AVLinearPCMBitDepthKey: 16,
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMIsFloatKey: false,
                AVLinearPCMIsNonInterleaved: false
            ]
            
            audioRecorder = try AVAudioRecorder(url: targetURL, settings: settings)
            audioRecorder?.isMeteringEnabled = true
            audioRecorder?.prepareToRecord()
            guard audioRecorder?.record() == true else {
                throw NSError(domain: "SpeechRecorder", code: -1, userInfo: [NSLocalizedDescriptionKey: "å½•éŸ³å¯åŠ¨å¤±è´¥ã€‚"])
            }
            
            speechRecordingURL = targetURL
            isRecordingSpeech = true
            resetRecordingVisuals()
            startRecordingTimer()
        } catch {
            presentSpeechError("å¼€å§‹å½•éŸ³å¤±è´¥: \(error.localizedDescription)")
            isSpeechRecorderPresented = false
            stopRecordingTimer(resetVisuals: true)
            audioRecorder = nil
            speechRecordingURL = nil
        }
    }
    
    func finishSpeechRecording() {
        guard isRecordingSpeech else { return }
        isRecordingSpeech = false
        audioRecorder?.stop()
        stopRecordingTimer()
        guard let url = speechRecordingURL else {
            audioRecorder = nil
            speechRecordingURL = nil
            isSpeechRecorderPresented = false
            presentSpeechError("å½•éŸ³æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ— æ³•å¤„ç†ã€‚")
            resetRecordingVisuals()
            return
        }
        
        if sendSpeechAsAudio && isSendingMessage {
            presentSpeechError("ä¸Šä¸€æ¡æ¶ˆæ¯ä»åœ¨å‘é€ï¼Œè¯·ç¨åå†è¯•ã€‚")
            try? FileManager.default.removeItem(at: url)
            audioRecorder = nil
            speechRecordingURL = nil
            isSpeechRecorderPresented = false
            resetRecordingVisuals()
            return
        }
        
        speechTranscriptionInProgress = true
        if sendSpeechAsAudio {
            isSpeechRecorderPresented = false
        }
        Task {
            defer {
                speechTranscriptionInProgress = false
                isSpeechRecorderPresented = false
                audioRecorder = nil
                speechRecordingURL = nil
                try? FileManager.default.removeItem(at: url)
                resetRecordingVisuals()
            }
            do {
                let data = try Data(contentsOf: url)
                if sendSpeechAsAudio {
                    let attachment = AudioAttachment(data: data, mimeType: "audio/wav", format: "wav", fileName: url.lastPathComponent)
                    var messageText = userInput.trimmingCharacters(in: .whitespacesAndNewlines)
                    if messageText.isEmpty {
                        messageText = "[è¯­éŸ³æ¶ˆæ¯]"
                    }
                    userInput = ""
                    await chatService.sendAndProcessMessage(
                        content: messageText,
                        aiTemperature: aiTemperature,
                        aiTopP: aiTopP,
                        systemPrompt: systemPrompt,
                        maxChatHistory: maxChatHistory,
                        enableStreaming: enableStreaming,
                        enhancedPrompt: currentSession?.enhancedPrompt,
                        enableMemory: enableMemory,
                        enableMemoryWrite: enableMemoryWrite,
                        includeSystemTime: includeSystemTimeInPrompt,
                        audioAttachment: attachment
                    )
                } else {
                    guard let speechModel = selectedSpeechModel else {
                        throw NSError(domain: "SpeechRecorder", code: -2, userInfo: [NSLocalizedDescriptionKey: "å°šæœªé€‰æ‹©è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹ã€‚"])
                    }
                    let transcript = try await chatService.transcribeAudio(
                        using: speechModel,
                        audioData: data,
                        fileName: url.lastPathComponent,
                        mimeType: "audio/wav"
                    )
                    appendTranscribedText(transcript)
                }
            } catch {
                presentSpeechError(error.localizedDescription)
            }
        }
    }
    
    func cancelSpeechRecording() {
        if isRecordingSpeech {
            audioRecorder?.stop()
            isRecordingSpeech = false
        }
        speechTranscriptionInProgress = false
        if let url = speechRecordingURL {
            try? FileManager.default.removeItem(at: url)
        }
        audioRecorder = nil
        speechRecordingURL = nil
        isSpeechRecorderPresented = false
        stopRecordingTimer(resetVisuals: true)
    }
    
    private func resetRecordingVisuals() {
        recordingDuration = 0
        waveformSamples = Array(repeating: 0, count: waveformSampleCount)
    }
    
    private func startRecordingTimer() {
        stopRecordingTimer()
        recordingStartDate = Date()
        recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.12, repeats: true) { [weak self] _ in
            Task { @MainActor [weak self] in
                self?.updateRecordingMetrics()
            }
        }
        if let timer = recordingTimer {
            RunLoop.main.add(timer, forMode: .common)
        }
    }
    
    private func stopRecordingTimer(resetVisuals: Bool = false) {
        recordingTimer?.invalidate()
        recordingTimer = nil
        recordingStartDate = nil
        if resetVisuals {
            resetRecordingVisuals()
        }
    }
    
    @MainActor
    private func updateRecordingMetrics() {
        guard let recorder = audioRecorder else { return }
        recorder.updateMeters()
        let power = recorder.averagePower(forChannel: 0)
        let normalizedLevel = max(0, min(1, (power + 60) / 60))
        recordingDuration = Date().timeIntervalSince(recordingStartDate ?? Date())
        var samples = waveformSamples
        samples.append(CGFloat(normalizedLevel))
        if samples.count > waveformSampleCount {
            samples.removeFirst(samples.count - waveformSampleCount)
        }
        waveformSamples = samples
    }
    
    // MARK: ä¼šè¯å’Œæ¶ˆæ¯ç®¡ç†
    
    func deleteMessage(at offsets: IndexSet) {
        // æ­¤æ–¹æ³•å·²åºŸå¼ƒï¼Œå› ä¸ºç›´æ¥æ“ä½œ messages æ•°ç»„ä¸å®‰å…¨
        // åº”è¯¥é€šè¿‡ message ID æ¥åˆ é™¤
    }
    
    func deleteMessage(_ message: ChatMessage) {
        chatService.deleteMessage(message)
    }
    
    func deleteSession(at offsets: IndexSet) {
        let sessionsToDelete = offsets.map { chatSessions[$0] }
        chatService.deleteSessions(sessionsToDelete)
    }
    
    func deleteSessions(_ sessions: [ChatSession]) {
        chatService.deleteSessions(sessions)
    }
    
    @discardableResult
    func branchSession(from sourceSession: ChatSession, copyMessages: Bool) -> ChatSession {
        return chatService.branchSession(from: sourceSession, copyMessages: copyMessages)
    }
    
    func deleteLastMessage(for session: ChatSession) {
        chatService.deleteLastMessage(for: session)
    }
    
    func createNewSession() {
        chatService.createNewSession()
    }
    
    // MARK: è®°å¿†ç®¡ç†
    
    func addMemory(content: String) async {
        await MemoryManager.shared.addMemory(content: content)
    }

    func updateMemory(item: MemoryItem) async {
        await MemoryManager.shared.updateMemory(item: item)
    }

    func deleteMemories(at offsets: IndexSet) async {
        let itemsToDelete = offsets.map { memories[$0] }
        await MemoryManager.shared.deleteMemories(itemsToDelete)
    }
    
    func reembedAllMemories() async throws -> MemoryReembeddingSummary {
        try await MemoryManager.shared.reembedAllMemories()
    }
    
    // MARK: è§†å›¾çŠ¶æ€ä¸æŒä¹…åŒ–
    
    func updateDisplayedMessages() {
        let filtered = visibleMessages(from: allMessagesForSession)
        let lazyCount = lazyLoadMessageCount
        if lazyCount > 0 && filtered.count > lazyCount {
            messages = Array(filtered.suffix(lazyCount))
            isHistoryFullyLoaded = false
        } else {
            messages = filtered
            isHistoryFullyLoaded = true
        }
    }

    func saveCurrentSessionDetails() {
        if let session = currentSession {
            chatService.updateSession(session)
        }
    }
    
    func commitEditedMessage(_ message: ChatMessage) {
        chatService.updateMessageContent(message, with: message.content)
        messageToEdit = nil
    }
    
    func updateSession(_ session: ChatSession) {
        chatService.updateSession(session)
    }
    
    func canRetry(message: ChatMessage) -> Bool {
        // å¦‚æœæ¶ˆæ¯æ­£åœ¨å‘é€ä¸­ï¼Œå…è®¸å¯¹æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯ä»¥åŠå¯¹åº”çš„ç”¨æˆ·æ¶ˆæ¯è¿›è¡Œé‡è¯•ã€‚
        if isSendingMessage {
            guard let lastMessage = allMessagesForSession.last else { return false }
            if lastMessage.id == message.id { return true }
            if let secondLast = allMessagesForSession.dropLast().last, secondLast.role == .user {
                return secondLast.id == message.id
            }
            return false
        }

        // åœ¨éå‘é€çŠ¶æ€ä¸‹çš„åŸå§‹é€»è¾‘ã€‚
        guard let lastUserMessageIndex = allMessagesForSession.lastIndex(where: { $0.role == .user }) else {
            return false
        }
        
        guard let messageIndex = allMessagesForSession.firstIndex(where: { $0.id == message.id }) else {
            return false
        }
        
        return messageIndex >= lastUserMessageIndex
    }
    
    // MARK: - ç§æœ‰æ–¹æ³• (å†…éƒ¨é€»è¾‘)
    
    private func refreshBackgroundImages() {
        let images = ConfigLoader.loadBackgroundImages()
        backgroundImages = images
        if !images.contains(currentBackgroundImage) {
            currentBackgroundImage = images.first ?? ""
        }
    }
    
    private func requestMicrophonePermission() async -> Bool {
        switch AVAudioApplication.shared.recordPermission {
        case .granted:
            return true
        case .denied:
            return false
        case .undetermined:
            return await withCheckedContinuation { continuation in
                AVAudioApplication.requestRecordPermission { granted in
                    continuation.resume(returning: granted)
                }
            }
        @unknown default:
            return false
        }
    }
    
    private func presentSpeechError(_ message: String) {
        speechErrorMessage = message
        showSpeechErrorAlert = true
    }
    
    private func syncSpeechModelSelection() {
        if let match = speechModels.first(where: { $0.id == speechModelIdentifier }) {
            if selectedSpeechModel?.id != match.id {
                selectedSpeechModel = match
            }
            return
        }
        guard !speechModelIdentifier.isEmpty else {
            selectedSpeechModel = nil
            return
        }
        guard !speechModels.isEmpty else {
            return
        }
        selectedSpeechModel = nil
        speechModelIdentifier = ""
    }
    
    private func syncEmbeddingModelSelection() {
        if let match = embeddingModelOptions.first(where: { $0.id == memoryEmbeddingModelIdentifier }) {
            if selectedEmbeddingModel?.id != match.id {
                selectedEmbeddingModel = match
            }
            return
        }
        guard !memoryEmbeddingModelIdentifier.isEmpty else {
            selectedEmbeddingModel = nil
            return
        }
        guard !embeddingModelOptions.isEmpty else {
            return
        }
        selectedEmbeddingModel = nil
        memoryEmbeddingModelIdentifier = ""
    }
    
    private func startExtendedSession() {
        extendedSession = WKExtendedRuntimeSession()
        extendedSession?.start()
    }
    
    private func stopExtendedSession() {
        extendedSession?.invalidate()
        extendedSession = nil
    }
    
    private func visibleMessages(from source: [ChatMessage]) -> [ChatMessage] {
        source.filter { message in
            if message.role == .tool,
               let calls = message.toolCalls,
               !calls.isEmpty,
               calls.allSatisfy({ $0.toolName == "save_memory" }) {
                return false
            }
            return true
        }
    }
}
